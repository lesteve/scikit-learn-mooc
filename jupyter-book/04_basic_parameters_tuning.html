
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction to scikit-learn: basic model hyper-parameters tuning &#8212; Scikit-learn tutorial</title>
    
  <link rel="stylesheet" href="_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/sphinx-book-theme.bfb7730f9caf2ec0b46a44615585038c.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Exercise 01" href="04_basic_parameters_tuning_exercise_01.html" />
    <link rel="prev" title="Solution for Exercise 03" href="03_basic_preprocessing_categorical_variables_exercise_02_solution.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/scikit-learn-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Scikit-learn tutorial</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Tabular data exploration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01_tabular_data_exploration.html">
   Loading data into machine learning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Fitting a scikit-learn model on numerical data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="02_basic_preprocessing.html">
   First model with scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_basic_preprocessing_exercise_01.html">
   Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_basic_preprocessing_exercise_01_solution.html">
   Solution for Exercise 01
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Fitting a scikit-learn model on numerical data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables.html">
   Working with both numerical &amp; categorical variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables.html#fitting-a-more-powerful-model">
   Fitting a more powerful model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_01.html">
   Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_01_solution.html">
   Solution for Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_02.html">
   Exercise 03
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_basic_preprocessing_categorical_variables_exercise_02_solution.html">
   Solution for Exercise 03
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Parameter tuning
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction to scikit-learn: basic model hyper-parameters tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_01.html">
   Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_01_solution.html">
   Exercise 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_02.html">
   Exercise 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_basic_parameters_tuning_exercise_02_solution.html">
   Exercise 02
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html">
   Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html#main-take-away">
   Main take away
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Decision Trees
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="trees.html">
   Decision tree in depth
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Ensemble models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble.html">
   Ensemble learning: when many are better that the one
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Metrics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="metrics.html">
   Evaluation of your predictive model
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Interpretation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html">
   Feature importance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dev_features_importance.html#take-away">
   Take Away
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/04_basic_parameters_tuning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/04_basic_parameters_tuning.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/INRIA/scikit-learn-mooc/master?urlpath=tree/python_scripts/04_basic_parameters_tuning.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quizz">
   Quizz
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-issue-of-finding-the-best-model-parameters">
   The issue of finding the best model parameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finding-the-best-model-hyper-parameters-via-exhaustive-parameters-search">
   Finding the best model hyper-parameters via exhaustive parameters search
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1">
   Exercise 1:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automated-parameter-tuning-via-grid-search">
   Automated parameter tuning via grid-search
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyper-parameter-tuning-with-random-search">
   Hyper-parameter tuning with Random Search
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2">
   Exercise 2:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#combining-evaluation-and-hyper-parameters-search">
   Combining evaluation and hyper-parameters search
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-this-notebook-we-have">
   In this notebook, we have:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main-take-away-points">
   Main take-away points
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-to-scikit-learn-basic-model-hyper-parameters-tuning">
<h1>Introduction to scikit-learn: basic model hyper-parameters tuning<a class="headerlink" href="#introduction-to-scikit-learn-basic-model-hyper-parameters-tuning" title="Permalink to this headline">¶</a></h1>
<p>The process of learning a predictive model is driven by a set of internal
parameters and a set of training data. These internal parameters are called
hyper-parameters and are specific for each family of models. In addition, a
specific set of hyper-parameters are optimal for a specific dataset and thus they
need to be optimized.
In this notebook we will use the words “hyper-parameters” and “parameters” interchangeably</p>
<p>This notebook shows:</p>
<ul class="simple">
<li><p>the influence of changing model hyper-parameters;</p></li>
<li><p>how to tune these hyper-parameters;</p></li>
<li><p>how to evaluate the model performance together with hyper-parameter
tuning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../datasets/adult-census.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target_name</span> <span class="o">=</span> <span class="s2">&quot;class&quot;</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">target_name</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">target</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target_name</span><span class="p">,</span> <span class="s2">&quot;fnlwgt&quot;</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Once the dataset is loaded, we split it into a training and testing sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="n">target_train</span><span class="p">,</span> <span class="n">target_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we define the preprocessing pipeline to transform differently
the numerical and categorical data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>

<span class="n">categorical_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;workclass&#39;</span><span class="p">,</span> <span class="s1">&#39;education&#39;</span><span class="p">,</span> <span class="s1">&#39;marital-status&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span>
    <span class="s1">&#39;relationship&#39;</span><span class="p">,</span> <span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;native-country&#39;</span><span class="p">,</span> <span class="s1">&#39;sex&#39;</span><span class="p">]</span>

<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">categorical_columns</span><span class="p">]]</span>

<span class="n">categorical_preprocessor</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">)</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;cat-preprocessor&#39;</span><span class="p">,</span> <span class="n">categorical_preprocessor</span><span class="p">,</span>
     <span class="n">categorical_columns</span><span class="p">),],</span> <span class="n">remainder</span><span class="o">=</span><span class="s1">&#39;passthrough&#39;</span><span class="p">,</span>
                                 <span class="n">sparse_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we use a tree-based classifier (i.e. histogram gradient-boosting) to
predict whether or not a person earns more than 50,000 dollars a year.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="c1"># for the moment this line is required to import HistGradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_hist_gradient_boosting</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;preprocessor&quot;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;classifier&quot;</span><span class="p">,</span>
     <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">target_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;The test accuracy score of the gradient boosting pipeline is: &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">df_test</span><span class="p">,</span> <span class="n">target_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="quizz">
<h2>Quizz<a class="headerlink" href="#quizz" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>What is the default value of the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> parameter of the
<code class="docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> class? (<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html">link to the API documentation</a>)</p></li>
<li><p>Try to edit the code of the previous cell to set the learning rate
parameter to 10. Does this increase the accuracy of the model?</p></li>
<li><p>Decrease progressively value of <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: can you find a value that
yields an accuracy higher than with the default learning rate?</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> to 0.05 and try setting the value of <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>
to the minimum value of 2. Does it improve the accuracy?</p></li>
<li><p>Try to progressively increase the value of <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> to 256 by
taking powers of 2. What do you observe?</p></li>
</ol>
</div>
<div class="section" id="the-issue-of-finding-the-best-model-parameters">
<h2>The issue of finding the best model parameters<a class="headerlink" href="#the-issue-of-finding-the-best-model-parameters" title="Permalink to this headline">¶</a></h2>
<p>In the previous example, we created an histogram gradient-boosting classifier
using the default parameters by omitting to explicitely set these parameters.</p>
<p>However, there is no reason that these parameters are optimal for our
dataset. For instance, fine-tuning the histogram gradient-boosting can be
achieved by finding the best combination of the following parameters: (i)
<code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>, (ii) <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, and (iii) <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>.
Nevertheless, finding this combination manually will be tedious. Indeed,
there are relationship between these parameters which are difficult to find
manually: increasing the depth of trees (increasing <code class="docutils literal notranslate"><span class="pre">max_samples_leaf</span></code>)
should be associated with a lower learning-rate.</p>
<p>Scikit-learn provides tools to explore and evaluate the parameters
space.</p>
</div>
<div class="section" id="finding-the-best-model-hyper-parameters-via-exhaustive-parameters-search">
<h2>Finding the best model hyper-parameters via exhaustive parameters search<a class="headerlink" href="#finding-the-best-model-hyper-parameters-via-exhaustive-parameters-search" title="Permalink to this headline">¶</a></h2>
<p>Our goal is to find the best combination of the parameters stated above.</p>
<p>In short, we will set these parameters with some defined values, train our
model on some data, and evaluate the model performance on some left out data.
Ideally, we will select the parameters leading to the optimal performance on
the testing set.</p>
<p>The first step is to find the name of the parameters to be set. We use the
method <code class="docutils literal notranslate"><span class="pre">get_params()</span></code> to get this information. For instance, for a single
model like the <code class="docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code>, we can get the list such as:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The hyper-parameters are for a histogram GBDT model are:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">(</span>
<span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When the model of interest is a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>, i.e. a serie of transformers and
a predictor, the name of the estimator will be added at the front of the
parameter name with a double underscore (“dunder”) in-between (e.g.
<code class="docutils literal notranslate"><span class="pre">estimator__parameters</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The hyper-parameters are for the full-pipeline are:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The parameters that we want to set are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'classifier__learning_rate'</span></code>: this parameter will
control the ability of a new tree to correct the error of the previous
sequence of trees;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'classifier__max_leaf_nodes'</span></code>: this parameter will
control the depth of each tree.</p></li>
</ul>
</div>
<div class="section" id="exercise-1">
<h2>Exercise 1:<a class="headerlink" href="#exercise-1" title="Permalink to this headline">¶</a></h2>
<p>By using the previously defined model (called <code class="docutils literal notranslate"><span class="pre">model</span></code>) and using two nested <code class="docutils literal notranslate"><span class="pre">for</span></code>
loops, make a search for the best combinations of the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> and
<code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> parameters. In this regard, you will need to train and test
the model by setting the parameters. The evaluation of the model should be
performed using <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code>. You can use the following parameters
search:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> for the values 0.05, 0.1, 0.5, 1 and 5</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> for the values 3, 10, 30 and 100</p></li>
</ul>
</div>
<div class="section" id="automated-parameter-tuning-via-grid-search">
<h2>Automated parameter tuning via grid-search<a class="headerlink" href="#automated-parameter-tuning-via-grid-search" title="Permalink to this headline">¶</a></h2>
<p>Instead of manually writing the two <code class="docutils literal notranslate"><span class="pre">for</span></code> loops, scikit-learn provides a
class called <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> which implement the exhaustive search implemented
during the exercise.</p>
<p>Let see how to use the <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> estimator for doing such search.
Since the grid-search will be costly, we will only explore the combination
learning-rate and the maximum number of nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;classifier__learning_rate&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="s1">&#39;classifier__max_leaf_nodes&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">100</span><span class="p">)}</span>
<span class="n">model_grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
                                 <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model_grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">target_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The test accuracy score of the grid-searched pipeline is: &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">df_test</span><span class="p">,</span> <span class="n">target_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> estimator takes a <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> parameter which defines
all hyper-parameters and their associated values. The grid-search will be in
charge of creating all possible combinations and test them.</p>
<p>The number of combinations will be equal to the product of the
number of values to explore for each parameter (e.g. in our example 4 x 4
combinations). Thus, adding new parameters with their associated values to be
explored become rapidly computationally expensive.</p>
<p>Once the grid-search is fitted, it can be used as any other predictor by
calling <code class="docutils literal notranslate"><span class="pre">predict</span></code> and <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>. Internally, it will use the model with
the best parameters found during <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
<p>Get predictions for the 5 first samples using the estimator with the best
parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_grid_search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>You can know about these parameters by looking at the <code class="docutils literal notranslate"><span class="pre">best_params_</span></code>
attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The best set of parameters is: &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The accuracy and the best parameters of the grid-searched pipeline are
similar to the ones we found in the previous exercise, where we searched the
best parameters “by hand” through a double for loop.</p>
<p>In addition, we can inspect all results which are stored in the attribute
<code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> of the grid-search. We will filter some specific columns
from these results</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
    <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">cv_results</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let us focus on the most interesting columns and shorten the parameter
names to remove the <code class="docutils literal notranslate"><span class="pre">&quot;param_classifier__&quot;</span></code> prefix for readability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># get the parameter names</span>
<span class="n">column_results</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;param_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
<span class="n">column_results</span> <span class="o">+=</span> <span class="p">[</span>
    <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span> <span class="s2">&quot;std_test_score&quot;</span><span class="p">,</span> <span class="s2">&quot;rank_test_score&quot;</span><span class="p">]</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="n">column_results</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">shorten_param</span><span class="p">(</span><span class="n">param_name</span><span class="p">):</span>
    <span class="k">if</span> <span class="s2">&quot;__&quot;</span> <span class="ow">in</span> <span class="n">param_name</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">param_name</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">param_name</span>


<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cv_results</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">shorten_param</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_results</span>
</pre></div>
</div>
</div>
</div>
<p>With only 2 parameters, we might want to visualize the grid-search as a
heatmap. We need to transform our <code class="docutils literal notranslate"><span class="pre">cv_results</span></code> into a dataframe where:</p>
<ul class="simple">
<li><p>the rows will correspond to the learning-rate values</p></li>
<li><p>the columns will correspond to the maximum number of leaf</p></li>
<li><p>the content of the dataframe will be the mean test scores.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pivoted_cv_results</span> <span class="o">=</span> <span class="n">cv_results</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span>
    <span class="n">values</span><span class="o">=</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;max_leaf_nodes&quot;</span><span class="p">])</span>

<span class="n">pivoted_cv_results</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">seaborn</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">(</span><span class="n">pivoted_cv_results</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;YlGnBu&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">vmax</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The above tables highlights the following things:</p>
<ul class="simple">
<li><p>for too high values of <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>, the performance of the model is degraded and adjusting the value of <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> cannot fix that problem;</p></li>
<li><p>outside of this pathological region, we observe that the optimal choice of <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> depends on the value of <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>;</p></li>
<li><p>in particular, we observe a “diagonal” of good models with an accuracy close to the maximal of 0.87: when the value of <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> is increased, one should increase the value of <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> accordingly to preserve a good accuracy.</p></li>
</ul>
<p>The precise meaning of those two parameters will be explained in a latter notebook.</p>
<p>For now we will note that, in general, <strong>there is no unique optimal parameter setting</strong>: 6 models out of the 16 parameter configuration reach the maximal accuracy (up to small random fluctuations caused by the sampling of the training set).</p>
</div>
<div class="section" id="hyper-parameter-tuning-with-random-search">
<h2>Hyper-parameter tuning with Random Search<a class="headerlink" href="#hyper-parameter-tuning-with-random-search" title="Permalink to this headline">¶</a></h2>
<p>With the <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> estimator, the parameters need to be specified
explicitly. We already mentioned that exploring a large number of values for
different parameters will be quickly untractable.</p>
<p>Instead, we can randomly generate the parameter candidates. The
<code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> allows for such stochastic search. It is used similarly to
the <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> but the sampling distributions need to be specified
instead of the parameter values. For instance, we will draw candidates using
a log-uniform distribution also called reciprocal distribution. In addition,
we will optimize 3 other parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter</span></code>: it corresponds to the number of trees in the ensemble;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>: it corresponds to the minimum number of samples
required in a leaf.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_bins</span></code>: it corresponds to the maximum number of bins to construct the
histograms.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">reciprocal</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>


<span class="k">class</span> <span class="nc">reciprocal_int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Integer valued version of the log-uniform distribution&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span> <span class="o">=</span> <span class="n">reciprocal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">rvs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Random variable sample&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>


<span class="n">param_distributions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;classifier__l2_regularization&#39;</span><span class="p">:</span> <span class="n">reciprocal</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">),</span>
    <span class="s1">&#39;classifier__learning_rate&#39;</span><span class="p">:</span> <span class="n">reciprocal</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="s1">&#39;classifier__max_leaf_nodes&#39;</span><span class="p">:</span> <span class="n">reciprocal_int</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
    <span class="s1">&#39;classifier__min_samples_leaf&#39;</span><span class="p">:</span> <span class="n">reciprocal_int</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
    <span class="s1">&#39;classifier__max_bins&#39;</span><span class="p">:</span> <span class="n">reciprocal_int</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">255</span><span class="p">),}</span>
<span class="n">model_random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_distributions</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model_random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span> <span class="n">target_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The test accuracy score of the best model is &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_random_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">df_test</span><span class="p">,</span> <span class="n">target_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The best parameters are:&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_random_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can inspect the results using the attributes <code class="docutils literal notranslate"><span class="pre">cv_results</span></code> as we previously
did.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># get the parameter names</span>
<span class="n">column_results</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">f</span><span class="s2">&quot;param_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">param_distributions</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
<span class="n">column_results</span> <span class="o">+=</span> <span class="p">[</span>
    <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span> <span class="s2">&quot;std_test_score&quot;</span><span class="p">,</span> <span class="s2">&quot;rank_test_score&quot;</span><span class="p">]</span>

<span class="n">cv_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_random_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="n">column_results</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
    <span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cv_results</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">shorten_param</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_results</span>
</pre></div>
</div>
</div>
</div>
<p>In practice, a randomized hyper-parameter search is usually run with a large number of
iterations. In order to avoid the computation cost and still make a decent
analysis, we load the results obtained from a similar search with 200
iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># model_random_search = RandomizedSearchCV(</span>
<span class="c1">#     model, param_distributions=param_distributions, n_iter=500,</span>
<span class="c1">#     n_jobs=4, cv=5)</span>
<span class="c1"># model_random_search.fit(df_train, target_train)</span>
<span class="c1"># cv_results =  pd.DataFrame(model_random_search.cv_results_)</span>
<span class="c1"># cv_results.to_csv(&quot;../figures/randomized_search_results.csv&quot;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../figures/randomized_search_results.csv&quot;</span><span class="p">,</span>
                         <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As we have more than 2 paramters in our grid-search, we cannot visualize the
results using a heatmap. However, we can us a parallel coordinates plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="n">column_results</span><span class="p">]</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
    <span class="n">shorten_param</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">parallel_coordinates</span><span class="p">(</span>
    <span class="n">cv_results</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">shorten_param</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">({</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">,</span>
        <span class="s2">&quot;max_leaf_nodes&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">,</span>
        <span class="s2">&quot;max_bins&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">,</span>
        <span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">,</span>
        <span class="s2">&quot;l2_regularization&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">,</span>
        <span class="s2">&quot;mean_test_score&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,}),</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span>
    <span class="n">color_continuous_scale</span><span class="o">=</span><span class="n">px</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">sequential</span><span class="o">.</span><span class="n">Viridis</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The parallel coordinates plot will display the values of the hyper-parameters
on different columns while the performance metric is color coded. Thus, we
are able to quickly inspect if there is a range of hyper-parameters which is
working or not.</p>
<p>Note that we <strong>transformed most axis values by taking a log10 or log2</strong> to
spread the active ranges and improve the readability of the plot.</p>
<p>It is possible to <strong>select a range of results by clicking and holding on
any axis</strong> of the parallel coordinate plot. You can then slide (move)
the range selection and cross two selections to see the intersections.</p>
<p><strong>Quizz</strong></p>
<p>Select the worst performing models (for instance models with a “mean_test_score” lower than 0.7): what do have all these moels in common (choose one):</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>too large <code class="docutils literal notranslate"><span class="pre">l2_regularization</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>too small <code class="docutils literal notranslate"><span class="pre">l2_regularization</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>too large <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>too low <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>too large <code class="docutils literal notranslate"><span class="pre">max_bins</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>too large <code class="docutils literal notranslate"><span class="pre">max_bins</span></code></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>Using the above plot, identify ranges of values for hyperparameter that always prevent the model to reach a test score higher than 0.86, irrespective of the other values:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>True</p></th>
<th class="head"><p>False</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>too large <code class="docutils literal notranslate"><span class="pre">l2_regularization</span></code></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>too small <code class="docutils literal notranslate"><span class="pre">l2_regularization</span></code></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>too large <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>too low <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>too large <code class="docutils literal notranslate"><span class="pre">max_bins</span></code></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>too large <code class="docutils literal notranslate"><span class="pre">max_bins</span></code></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="exercise-2">
<h2>Exercise 2:<a class="headerlink" href="#exercise-2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Build a machine learning pipeline:</p>
<ul>
<li><p>preprocess the categorical columns using a <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> and use
a <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> to normalize the numerical data.</p></li>
<li><p>use a <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> as a predictive model.</p></li>
</ul>
</li>
<li><p>Make an hyper-parameters search using <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> and tuning the
parameters:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code> with values ranging from 0.001 to 10. You can use a reciprocal
distribution (i.e. <code class="docutils literal notranslate"><span class="pre">scipy.stats.reciprocal</span></code>);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">solver</span></code> with possible values being <code class="docutils literal notranslate"><span class="pre">&quot;liblinear&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;lbfgs&quot;</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">penalty</span></code> with possible values being <code class="docutils literal notranslate"><span class="pre">&quot;l2&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;l1&quot;</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop</span></code> with possible values being <code class="docutils literal notranslate"><span class="pre">None</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;first&quot;</span></code>.</p></li>
</ul>
</li>
</ul>
<p>You might get some <code class="docutils literal notranslate"><span class="pre">FitFailedWarning</span></code> and try to explain why.</p>
</div>
<div class="section" id="combining-evaluation-and-hyper-parameters-search">
<h2>Combining evaluation and hyper-parameters search<a class="headerlink" href="#combining-evaluation-and-hyper-parameters-search" title="Permalink to this headline">¶</a></h2>
<p>Cross-validation was used for searching for the best model parameters. We
previously evaluated model performance through cross-validation as well. If
we would like to combine both aspects, we need to perform a <strong>“nested”
cross-validation</strong>. The “outer” cross-validation is applied to assess the model
while the “inner” cross-validation sets the hyper-parameters of the model on
the data set provided by the “outer” cross-validation.</p>
<p>In practice, it can be implemented by calling <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> or
<code class="docutils literal notranslate"><span class="pre">cross_validate</span></code> on an instance of <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>, or any
other <code class="docutils literal notranslate"><span class="pre">EstimatorCV</span></code> class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># recall the definition of our grid-search</span>
<span class="n">param_distributions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;classifier__max_iter&#39;</span><span class="p">:</span> <span class="n">reciprocal_int</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="s1">&#39;classifier__learning_rate&#39;</span><span class="p">:</span> <span class="n">reciprocal</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="s1">&#39;classifier__max_leaf_nodes&#39;</span><span class="p">:</span> <span class="n">reciprocal_int</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
    <span class="s1">&#39;classifier__min_samples_leaf&#39;</span><span class="p">:</span> <span class="n">reciprocal_int</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">),}</span>
<span class="n">model_random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">param_distributions</span><span class="o">=</span><span class="n">param_distributions</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_random_search</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                         <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The cross-validated accuracy score is:&quot;</span>
      <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> +- </span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The scores obtained for each CV split are:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Be aware that the best model found for each split of the outer cross-validation loop might not share the same hyper-parameter values.</p>
<p>When analyzing such model, you should not only look at the
overall model performance but look at the hyper-parameters variations as
well.</p>
</div>
<div class="section" id="in-this-notebook-we-have">
<h2>In this notebook, we have:<a class="headerlink" href="#in-this-notebook-we-have" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>manually tuned the hyper-parameters of a machine-learning pipeline;</p></li>
<li><p>automatically tuned the hyper-parameters of a machine-learning pipeline by
exhaustively searching the best combination from a defined grid;</p></li>
<li><p>automatically tuned the hyper-parameters of a machine-learning pipeline by
drawing values candidates from some predefined distributions;</p></li>
<li><p>nested an hyper-parameters tuning procedure within a cross-validation
evaluation procedure.</p></li>
</ul>
</div>
<div class="section" id="main-take-away-points">
<h2>Main take-away points<a class="headerlink" href="#main-take-away-points" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>a grid-search is a costly exhaustive search and does scale with the number of
parameters to search;</p></li>
<li><p>a randomized-search will always run with a fixed given budget;</p></li>
<li><p>when assessing the performance of a model, hyper-parameters search should
be tuned on the training data of a predifined train test split;</p></li>
<li><p>alternatively it is possible to nest parameter tuning within a
cross-validation scheme.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="03_basic_preprocessing_categorical_variables_exercise_02_solution.html" title="previous page">Solution for Exercise 03</a>
    <a class='right-next' id="next-link" href="04_basic_parameters_tuning_exercise_01.html" title="next page">Exercise 01</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By scikit-learn developers<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.30270b6e4c972e43c488.js"></script>


    
  </body>
</html>